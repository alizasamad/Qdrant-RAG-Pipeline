,metric,bge-reranker_BM25_25_mean,default_bge-reranker_mean,mean_diff,improved,regressed,p_value,significant,CI_95_low,CI_95_high,effect_size
0,context_precision_score,0.6666666665999998,0.593333333274,0.073333333326,True,False,0.25586738806228515,False,,,-0.259235749277754
1,context_recall_score,0.6155555555555555,0.567,0.04855555555555556,True,False,0.28952314247664507,False,,,-0.19633251593511358
2,non_LLM_context_recall_score,0.0,0.0,0.0,False,False,,False,,,
3,rouge_score,0.4347893272065977,0.4072520202119479,0.02753730699464982,True,False,0.29683455534046205,False,,,-0.1675293964286168
4,answer_relevancy_score,0.8249237521195267,0.7730424069822268,0.05188134513729983,True,False,0.07885790741956278,False,,,-0.3053306635581485
5,answer_faithfulness_score,0.853534352902,0.8126253436106378,0.04090900929136223,True,False,0.11551306440298155,False,,,-0.32747612118459635
6,rag_latency,18.105428579648336,13.01619158109029,5.089236998558045,False,True,2.7975890552808727e-22,True,4.5111607644625185,5.673340211769262,-3.4222003782679056
