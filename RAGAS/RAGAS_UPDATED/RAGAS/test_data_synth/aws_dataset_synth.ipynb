{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04cb9ebf",
   "metadata": {},
   "source": [
    "## Synthetic RAG Dataset creation by AWS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d37d6294",
   "metadata": {},
   "source": [
    "### Step 1: Loading the Data\n",
    "\n",
    "This section will create chunks from your preferred document based on the parameters defined in 'AWS_data_creation.py'. You will then randomly sample `n` number of chunks to generate your synthetic RAG dataset. To keep document chunks constant across all methods, the chunks will be exported as a pickle file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3142bdc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adjustable parameters\n",
    "folder_name = \"policy_docs\"  # folder containing original source\n",
    "filename = \"CFR-2025-title5-vol1.pdf\"  # target policy\n",
    "doc_tag = 't5'  # abbreviated policy tag\n",
    "n = 100  # number of document chunks to sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7242157",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-05 17:50:11,653 - botocore.credentials - INFO - Found credentials from IAM Role: OCHCO-Analytics-SSM-CloudWatch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average length among 965 pages loaded is 4041 characters.\n",
      "After the split you have 3196\n",
      "Average length among 3196 chunks is 1274 characters.\n"
     ]
    }
   ],
   "source": [
    "from AWS_data_creation import chunk_doc, generate_dataset\n",
    "import pandas as pd \n",
    "import random\n",
    "import pickle\n",
    "\n",
    "# randomly sample document chunks\n",
    "random.seed(42)\n",
    "docs = chunk_doc(folder_name, filename)\n",
    "sampled_docs = random.sample(docs, n) #without replacement\n",
    "\n",
    "# store document chunks in folder defined above\n",
    "## documents will be reused for naive & ragas dataset generation methods\n",
    "with open(f\"{folder_name}/{doc_tag}.pk\", 'wb') as fi:\n",
    "    pickle.dump(sampled_docs, fi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6cbe1d",
   "metadata": {},
   "source": [
    "### Step 2: Generating the Dataset\n",
    "\n",
    "This process takes about 12 minutes for a sample size of n=100. At the end, you should have generated n questions- one q/a pair per chunk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0183bb93",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.DataFrame(columns=[\"question\", \"question_compressed\", \"reference_answer\", \"source_sentence\",\"source_raw\",\"source_document\"])  \n",
    "dataset_df = generate_dataset(sampled_docs, dataset)\n",
    "num_questions_generated = dataset_df.shape[0]\n",
    "print(f\"Generated a total of {num_questions_generated} questions.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa3f5148",
   "metadata": {},
   "source": [
    "### Step 3: Save Your Synthetic Dataset\n",
    "\n",
    "We will be evaluating this dataset along with the RAGAS and naive datasets generated from the same policy doc chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f787ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import os\n",
    "\n",
    "os.chdir('../')\n",
    "dataset_df.to_csv(f\"datasets/test-set-aws-synth-{n}-{doc_tag}.csv\", index=False)\n",
    "dataset_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.13.0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
