,metric,splitter_token_mean,default_mean,mean_diff,improved,regressed,p_value,significant,CI_95_low,CI_95_high,effect_size
0,context_precision_score,0.71527777770625,0.6944444443750001,0.02083333333125,True,False,0.7349248794650344,False,,,-0.08431916544867138
1,context_recall_score,0.7430555555555555,0.6319444444444444,0.11111111111111112,True,False,0.024017643210654062,True,0.03472222222222222,0.20138888888888887,-0.41392926267096536
2,non_LLM_context_recall_score,0.09722222222222221,0.027777777777777776,0.06944444444444443,True,False,0.018683874841108398,True,0.020833333333333332,0.13194444444444442,-0.4564354645876384
3,rouge_score,0.09482982718622086,0.18780722769923933,-0.09297740051301846,False,True,2.5285387197061893e-09,True,-0.11848328612538772,-0.0694133692348024,1.213133303471134
4,answer_relevancy_score,0.7323561642782943,0.6923802451453006,0.0399759191329938,True,False,0.2313401617459957,False,,,-0.22625024816843364
5,answer_faithfulness_score,0.9038974239495072,0.8686342592592592,0.03526316469024803,True,False,0.1651167586804202,False,,,-0.2854775262973426
6,rag_latency,5.377602842119006,3.7947683268123207,1.5828345153066845,False,True,1.602744426209829e-18,True,1.3818718147460278,1.8148248063746377,-2.697533915275815
