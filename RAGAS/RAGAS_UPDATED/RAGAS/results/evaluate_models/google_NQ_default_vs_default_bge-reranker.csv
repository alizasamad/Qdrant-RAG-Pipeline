,metric,default_bge-reranker_mean,default_mean,mean_diff,improved,regressed,p_value,significant,CI_95_low,CI_95_high,effect_size
0,context_precision_score,0.78472222214375,0.6944444443750001,0.09027777776875001,True,False,0.012387599015757351,True,0.006944444443750007,0.16666666665000002,-0.34288419005779835
1,context_recall_score,0.8090277777777777,0.6319444444444444,0.17708333333333334,True,False,0.0002635374499765932,True,0.09375,0.25,-0.6707068325394103
2,non_LLM_context_recall_score,0.041666666666666664,0.027777777777777776,0.01388888888888889,True,False,0.5270892568655381,False,,,-0.12226655067825488
3,rouge_score,0.1016360367230112,0.18780722769923933,-0.08617119097622811,False,True,1.075942064488579e-07,True,-0.11348261833746286,-0.05965722028879211,1.1880306846806046
4,answer_relevancy_score,0.7465402570602396,0.6923802451453006,0.05416001191493905,True,False,0.11844241250981469,False,,,-0.3140231571319944
5,answer_faithfulness_score,0.9225970017636684,0.8686342592592592,0.05396274250440917,True,False,0.02401850807407295,True,0.012115286050409546,0.10064792811591301,-0.45476858931716285
6,rag_latency,26.725886576705506,3.7947683268123207,22.93111824989319,False,True,1.009769898516011e-44,True,22.153519830639958,23.735351035660447,-11.441043841508352
