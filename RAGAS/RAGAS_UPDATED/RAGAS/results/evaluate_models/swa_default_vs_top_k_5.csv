,metric,top_k_5_mean,default_mean,mean_diff,improved,regressed,p_value,significant,CI_95_low,CI_95_high,effect_size
0,context_precision_score,0.4999999999499999,0.3999999999599999,0.09999999998999998,True,False,0.0696304432990882,False,,,-0.36418618720013035
1,context_recall_score,0.4595555555555556,0.3837777777777777,0.07577777777777779,True,False,0.06252034770693526,False,,,-0.28457546279815765
2,non_LLM_context_recall_score,0.0,0.0,0.0,False,False,,False,,,
3,rouge_score,0.3442080489719281,0.3293269266534617,0.01488112231846638,True,False,0.4832701169876352,False,,,-0.10953837544848803
4,answer_relevancy_score,0.7203318812467807,0.6389068910734071,0.08142499017337368,True,False,0.03845307144157756,True,0.009294661612475401,0.15911541253841943,-0.3452801716151302
5,answer_faithfulness_score,0.7966022670140316,0.8362501825659721,-0.03964791555194034,False,True,0.09964773765419484,False,,,0.2937171459877175
6,rag_latency,5.688420311609904,5.417910820643106,0.27050949096679694,False,True,0.020317884245355453,True,0.042990570131753475,0.4812779243502736,-0.38531531990958523
