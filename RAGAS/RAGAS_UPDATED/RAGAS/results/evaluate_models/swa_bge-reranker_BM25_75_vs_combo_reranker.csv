,metric,combo_reranker_mean,bge-reranker_BM25_75_mean,mean_diff,improved,regressed,p_value,significant,CI_95_low,CI_95_high,effect_size
0,context_precision_score,0.795918367267347,0.7074829931265305,0.08843537414081634,True,False,0.15784502667922318,False,,,-0.3387137019221829
1,context_recall_score,0.7054421768707482,0.6622448979591837,0.043197278911564614,True,False,0.43320944866256295,False,,,-0.17663398126049018
2,non_LLM_context_recall_score,0.0,0.0,0.0,False,False,,False,,,
3,rouge_score,0.4355434598775188,0.449305313368501,-0.013761853490982245,False,True,0.6351858485630815,False,,,0.08730938998945242
4,answer_relevancy_score,0.8597617016535308,0.8280506260197772,0.03171107563375371,True,False,0.38465097602651,False,,,-0.20306171719317667
5,answer_faithfulness_score,0.8446475893638971,0.8574744322193302,-0.012826842855433238,False,True,0.5740998884663857,False,,,0.10290056667470879
6,rag_latency,48.12748433943508,18.21486933863893,29.91261500079615,False,True,3.552713678800501e-15,True,27.886917479216876,34.00366938762113,-4.1693507313943785
