,metric,splitter_markdown_mean,default_mean,mean_diff,improved,regressed,p_value,significant,CI_95_low,CI_95_high,effect_size
0,context_precision_score,0.6944444443750001,0.6944444443750001,0.0,False,False,0.7262634041526131,False,,,0.0
1,context_recall_score,0.6180555555555555,0.6319444444444444,-0.013888888888888886,False,True,0.3651959278376957,False,,,0.05376363924892993
2,non_LLM_context_recall_score,0.027777777777777776,0.027777777777777776,0.0,False,False,1.0,False,,,0.0
3,rouge_score,0.09027965140844225,0.18780722769923933,-0.09752757629079706,False,True,2.2180451774710196e-09,True,-0.12264395792526742,-0.07054673799775457,1.3628161614158327
4,answer_relevancy_score,0.6505163676592651,0.6923802451453006,-0.04186387748603554,False,True,0.5655073098421042,False,,,0.2123692851554697
5,answer_faithfulness_score,0.8916257546465879,0.8686342592592592,0.022991495387328725,True,False,0.5343972978724334,False,,,-0.18852681605174113
6,rag_latency,4.652669307258393,3.7947683268123207,0.8579009804460737,False,True,2.173715158424162e-16,True,0.7207189327780512,0.9868151368609454,-2.199757811498315
