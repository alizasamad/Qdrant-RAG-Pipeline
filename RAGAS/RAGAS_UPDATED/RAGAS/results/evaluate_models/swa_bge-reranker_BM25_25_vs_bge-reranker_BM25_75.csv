,metric,bge-reranker_BM25_75_mean,bge-reranker_BM25_25_mean,mean_diff,improved,regressed,p_value,significant,CI_95_low,CI_95_high,effect_size
0,context_precision_score,0.6933333332639999,0.6666666665999998,0.026666666664000003,True,False,0.4281751726571018,False,,,-0.09772067378636895
1,context_recall_score,0.649,0.6155555555555555,0.03344444444444445,True,False,0.4154163070456176,False,,,-0.1376788319735638
2,non_LLM_context_recall_score,0.0,0.0,0.0,False,False,,False,,,
3,rouge_score,0.4437261234797142,0.4347893272065977,0.008936796273116457,True,False,0.7431959205512593,False,,,-0.05457248296051454
4,answer_relevancy_score,0.824081295802638,0.8249237521195267,-0.0008424563168887556,False,True,0.9618478594751583,False,,,0.005115606108589616
5,answer_faithfulness_score,0.8579439911939911,0.853534352902,0.004409638291991239,True,False,0.841982549989702,False,,,-0.03873448229928002
6,rag_latency,18.266044344902042,18.105428579648336,0.16061576525370275,False,True,0.49080829707326956,False,,,-0.11359028287247117
