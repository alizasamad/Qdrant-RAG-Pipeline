,metric,top_k_10_mean,default_mean,mean_diff,improved,regressed,p_value,significant,CI_95_low,CI_95_high,effect_size
0,context_precision_score,0.653333333268,0.3999999999599999,0.253333333308,True,False,0.00019662688707197968,True,0.13999999998600002,0.36666666663,-0.9266549090078519
1,context_recall_score,0.588111111111111,0.3837777777777777,0.20433333333333337,True,False,0.00017860156539638208,True,0.10277777777777779,0.29844444444444446,-0.8014385560742885
2,non_LLM_context_recall_score,0.0,0.0,0.0,False,False,,False,,,
3,rouge_score,0.37217485291272034,0.3293269266534617,0.042847926259258616,True,False,0.07323064213593045,False,,,-0.3391525383985952
4,answer_relevancy_score,0.8184956518876995,0.6389068910734071,0.17958876081429215,True,False,2.5685558997171162e-05,True,0.10695198387527169,0.25963012836478705,-0.8833529409140168
5,answer_faithfulness_score,0.7955316453698806,0.8362501825659721,-0.040718537196091385,False,True,0.11030258236886185,False,,,0.265013647936809
6,rag_latency,6.59897935072581,5.417910820643106,1.1810685300827028,False,True,2.464990871360817e-09,True,0.8474799673225806,1.4816245601027795,-1.4214734628861267
