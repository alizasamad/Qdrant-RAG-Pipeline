,metric,split_char_512_50_mean,split_char_2048_200_mean,mean_diff,improved,regressed,p_value,significant,CI_95_low,CI_95_high,effect_size
0,context_precision_score,0.31999999996799994,0.393333333294,-0.07333333332599999,False,True,0.28836554970762573,False,,,0.261618891604648
1,context_recall_score,0.27888888888888885,0.36666666666666664,-0.08777777777777775,False,True,0.09838675603746139,False,,,0.3478847572708147
2,non_LLM_context_recall_score,0.0,0.0,0.0,False,False,,False,,,
3,rouge_score,0.32598915545680446,0.30954218866024974,0.01644696679655476,True,False,0.4166252617968862,False,,,-0.13349908515594458
4,answer_relevancy_score,0.5418870919236847,0.6000882654754444,-0.05820117355175982,False,True,0.24513084584396871,False,,,0.22474018128413423
5,answer_faithfulness_score,0.7935147075147074,0.8675990110107756,-0.0740843034960682,False,True,0.004779750850619822,True,-0.11989756447052398,-0.020794745369158794,0.5771223454496275
6,rag_latency,5.1673305177688595,5.6694397989908865,-0.5021092812220256,True,False,0.00010832152845089435,True,-0.7330012109290954,-0.2728869933927503,0.7421095834509357
