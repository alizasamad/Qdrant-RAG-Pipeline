,metric,mean,std_btwn_samples,mean_std_wtn_sample,ci_95_lower,ci_95_upper,cv_btwn_samples,cv_wtn_sample
0,rag_latency,0.49457902520480634,0.21277639820012842,0.12052604234165018,0.43410864191262255,0.5550494084969901,0.43021718948153376,0.24369420496904426
1,context_precision_score,0.33999999996599994,0.2788069821898057,0.3111269836909682,0.2607639323374032,0.4192360675945967,0.820020535934372,0.9150793638884733
2,context_recall_score,0.3188015873015873,0.2465819103481842,0.2788377305457556,0.24872378375850338,0.38887939084467127,0.7734651274333741,0.8746434825055442
3,non_LLM_context_recall_score,0.0,0.0,0.0,0.0,0.0,,
4,rouge_score,0.3984943373127902,0.13067606791574304,0.17606170229908868,0.3613566097225896,0.43563206490299083,0.32792452910860675,0.4418173254012705
5,answer_relevancy_score,0.5996880939119118,0.24810642444467526,0.32348601895324663,0.5291770282564462,0.6701991595673774,0.4137257800571235,0.5394237808575928
6,answer_faithfulness_score,0.8631841491841492,0.10169470010907254,0.13278590125151857,0.8342828351925695,0.8920854631757289,0.11781344711344705,0.15383264553342765
