,metric,mean,std_btwn_samples,mean_std_wtn_sample,ci_95_lower,ci_95_upper,cv_btwn_samples,cv_wtn_sample
0,rag_latency,0.45656384961532837,0.18544358471352848,0.08547935135647565,0.4038613659678876,0.5092663332627692,0.4061722908411856,0.18722321407727552
1,context_precision_score,0.6666666665999998,0.26666666664000005,0.32055507410584605,0.5908808384753838,0.7424524947246159,0.4000000000000002,0.48083261120685244
2,context_recall_score,0.6155555555555555,0.23996913381763332,0.2904054961591757,0.5473570823085501,0.683754028802561,0.38984155313333935,0.4717778818470364
3,non_LLM_context_recall_score,0.0,0.0,0.0,0.0,0.0,,
4,rouge_score,0.4347893272065978,0.16313323429958906,0.16139803557825808,0.38842737499180646,0.48115127942138913,0.375200641072943,0.37120974568349274
5,answer_relevancy_score,0.824923752119527,0.1549181565270416,0.1537303001731824,0.7808964991753464,0.8689510050637075,0.1877969401765932,0.1863569812097103
6,answer_faithfulness_score,0.853534352902,0.10962523324829422,0.13673454810038443,0.8223792063298488,0.8846894994741511,0.12843681437726623,0.16019806072888534
