,metric,mean,std_btwn_samples,mean_std_wtn_sample,ci_95_lower,ci_95_upper,cv_btwn_samples,cv_wtn_sample
0,rag_latency,0.2988625869980639,0.18123112105648714,0.13127797341552916,0.24735727227584428,0.35036790172028354,0.6064028384310988,0.4392586396783737
1,context_precision_score,0.39999999996,0.26666666664000005,0.35826743576535736,0.3242141718353839,0.4757858280846161,0.6666666666666667,0.8956685895029602
2,context_recall_score,0.3837777777777778,0.257904279305231,0.29768682506085004,0.31048219258033866,0.4570733629752169,0.672014624709635,0.7756749929205704
3,non_LLM_context_recall_score,0.0,0.0,0.0,0.0,0.0,,
4,rouge_score,0.3293269266534617,0.1229448156206395,0.15422194074416626,0.29438639665457367,0.3642674566523497,0.37332147987403924,0.46829435513011725
5,answer_relevancy_score,0.6389068910734071,0.2366943683424118,0.29163125879829555,0.5716390958769457,0.7061746862698686,0.37046770296177134,0.45645345647835345
6,answer_faithfulness_score,0.8362501825659721,0.11827679300913117,0.14900914535170443,0.8026362899146576,0.8698640752172865,0.1414370908072122,0.17818727990525615
