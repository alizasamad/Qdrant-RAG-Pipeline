,metric,mean,std_btwn_samples,mean_std_wtn_sample,ci_95_lower,ci_95_upper,cv_btwn_samples,cv_wtn_sample
0,rag_latency,0.17464800060717853,0.17572088693004767,0.13968680108042553,0.12417506876401975,0.22512093245033732,1.006143135444661,0.7998190680385264
1,context_precision_score,0.7959183672673468,0.2592184881816652,0.20203050889023907,0.7214621241020808,0.8703746104326128,0.32568476723517353,0.25383320350286326
2,context_recall_score,0.7054421768707482,0.25824643113438905,0.21897625959086364,0.631265141089146,0.7796192126523503,0.3660773903255082,0.3104099340391221
3,non_LLM_context_recall_score,0.0,0.0,0.0,0.0,0.0,,
4,rouge_score,0.43554345987751875,0.15411783460691375,0.16153795419681255,0.39127564915888396,0.4798112705961535,0.353851793918003,0.37088825588665575
5,answer_relevancy_score,0.8597617016535309,0.13716877963267035,0.12125570610584688,0.8203622279406244,0.8991611753664375,0.15954278885516932,0.14103408639003417
6,answer_faithfulness_score,0.844647589363897,0.12959965723615188,0.12349073807663379,0.8074222214474407,0.8818729572803532,0.1534363666789758,0.14620386020356077
