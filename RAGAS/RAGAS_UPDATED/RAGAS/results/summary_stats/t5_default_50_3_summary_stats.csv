,metric,mean,std_btwn_samples,mean_std_wtn_sample,ci_95_lower,ci_95_upper,cv_btwn_samples,cv_wtn_sample
0,rag_latency,0.4483708834309567,0.19795288834985278,0.12891181770313634,0.39211329502563125,0.5046284718362822,0.4414936287457099,0.2875115723766373
1,context_precision_score,0.3666666666299999,0.29999999997,0.3016988932760904,0.28140760998980685,0.451925723270193,0.8181818181818183,0.8228151635625283
2,context_recall_score,0.3568253968253968,0.2876596470872449,0.27688554165730056,0.27507342967019044,0.4385773639806032,0.8061636017124746,0.7759692671000861
3,non_LLM_context_recall_score,0.0,0.0,0.0,0.0,0.0,,
4,rouge_score,0.39147427660802064,0.16093508574941404,0.1394610264250941,0.3457370312991015,0.4372115219169398,0.41110002716872446,0.35624569673765577
5,answer_relevancy_score,0.5851945253259734,0.25736895464014287,0.320864861845791,0.5120510777150217,0.6583379729369251,0.43980068763763563,0.5483046200185456
6,answer_faithfulness_score,0.8671857439945676,0.10270464215396675,0.1277306028908508,0.8379974076495961,0.8963740803395391,0.11843442176629017,0.14729324573819444
