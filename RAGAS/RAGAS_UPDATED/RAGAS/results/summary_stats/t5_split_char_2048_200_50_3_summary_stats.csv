,metric,mean,std_btwn_samples,mean_std_wtn_sample,ci_95_lower,ci_95_upper,cv_btwn_samples,cv_wtn_sample
0,rag_latency,0.4128328014669544,0.21297507407965563,0.14556107253480527,0.3523059551145461,0.4733596478193627,0.5158869966797041,0.35259086007112456
1,context_precision_score,0.519999999948,0.27616420233515665,0.36769552618023515,0.4415150020438619,0.5984849978521379,0.5310850045437944,0.7071067811865476
2,context_recall_score,0.5043888888888888,0.26867191084855213,0.3580075500030528,0.4280331766657012,0.5807446011120764,0.5326681787943539,0.7097847670508813
3,non_LLM_context_recall_score,0.0,0.0,0.0,0.0,0.0,,
4,rouge_score,0.43156002874384525,0.13315113853971303,0.18765791617609953,0.3937188938651825,0.469401163622508,0.30853445562898874,0.4348361842553424
5,answer_relevancy_score,0.6432003765132174,0.2721442200259751,0.2666583741657589,0.5658578449404972,0.7205429080859376,0.423109547138741,0.4145805629208602
6,answer_faithfulness_score,0.843638590168002,0.12168180736460413,0.1559321948781151,0.8090570031439444,0.8782201771920597,0.1442345203061093,0.18483293284042732
